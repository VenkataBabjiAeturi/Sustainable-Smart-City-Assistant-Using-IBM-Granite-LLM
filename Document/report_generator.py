# backend/services/report_generator.py

from typing import List
from backend.services.granite_llmservice import call_granite_llm

def generate_summary_report(kpi_data: List[dict], title: str = "Sustainability KPI Report") -> str:
    """
    Generates a textual summary report based on KPI data using IBM Granite LLM.

    Args:
        kpi_data (List[dict]): List of dictionaries representing time series or structured KPI data.
        title (str): Optional report title.

    Returns:
        str: A natural-language summary report generated by the LLM.
    """

    # Format data into a readable prompt
    formatted_data = "\n".join(
        [", ".join([f"{k}: {v}" for k, v in row.items()]) for row in kpi_data]
    )

    prompt = (
        f"Title: {title}\n\n"
        "You are an AI assistant that helps city administrators understand sustainability KPIs.\n"
        "Based on the following data, write a concise report (4-6 sentences) highlighting any patterns, trends, or concerns:\n\n"
        f"{formatted_data}"
    )

    # Call the Granite LLM
    report = call_granite_llm(prompt, max_tokens=350, temperature=0.6)
    return report


def generate_policy_digest(policy_text: str) -> str:
    """
    Summarizes a long-form city policy document into a citizen-friendly report.

    Args:
        policy_text (str): Raw text of the policy document.

    Returns:
        str: AI-generated summary of the policy.
    """
    prompt = (
        "You are a city planning assistant. Summarize the following city policy in clear, plain English "
        "so citizens can easily understand the main points:\n\n"
        f"{policy_text}"
    )
    return call_granite_llm(prompt, max_tokens=300)
